{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6U5h0usKfNMsUl6l4DwBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madathanapalleleena/ML_LAB_152/blob/main/ML_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBSCAN** stands for **Density-Based Spatial Clustering of Applications with Noise**.\n",
        "\n",
        "Unlike algorithms like k-means, DBSCAN does not require the number of clusters in advance.\n",
        "Instead, it groups points based on density - areas with many nearby points are considered clusters, while sparse regions are treated as noise (outliers)."
      ],
      "metadata": {
        "id": "f3VGq4q7CgqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCSBkQd4Bi7h",
        "outputId": "3868e76c-7269-40ea-d158-2d3d667917e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Results: {'moons': {'silhouette': np.float64(0.3893383378360491), 'ARI': 1.0}, 'circles': {'silhouette': -1, 'ARI': 0.0}, 'blobs': {'silhouette': np.float64(0.8438960565792794), 'ARI': 1.0}, 'iris': {'silhouette': np.float64(0.35651648142700726), 'ARI': 0.4420986685885924}}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_moons, make_circles, make_blobs, load_iris\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "#Prepare datasets- here we are creating 4 datasets where each dataset return X,y\n",
        "datasets = {\n",
        "    \"moons\": make_moons(n_samples=500, noise=0.05, random_state=42),\n",
        "    \"circles\": make_circles(n_samples=500, noise=0.05, factor=0.5, random_state=42),\n",
        "    \"blobs\": make_blobs(n_samples=500, centers=3, random_state=42, cluster_std=1.0),\n",
        "    \"iris\": (load_iris().data, load_iris().target)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, (X, y_true) in datasets.items():\n",
        "    X = StandardScaler().fit_transform(X)  #standardizing to prevent outliers\n",
        "    db = DBSCAN(eps=0.5, min_samples=5).fit(X) #eps- radius around a point to look for its neighbors, min_samples- min no.of neighbors should be around to be considered as core point with eps.\n",
        "    labels=db.labels_ #predicted cluster labels\n",
        "\n",
        "    #only evaluate if clustering produced more than 1 cluster\n",
        "    if len(set(labels)) > 1:\n",
        "        sil=silhouette_score(X, labels)\n",
        "    else:\n",
        "        sil=-1  #invalid clustering\n",
        "\n",
        "    ari=adjusted_rand_score(y_true, labels)\n",
        "    results[name] = {\"silhouette\": sil, \"ARI\": ari}\n",
        "\n",
        "print(\"Baseline Results:\",results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Silhouette Score** is a measure of how well clusters are seperated.\n",
        "\n",
        "It tells you two things at once:\n",
        "\n",
        "How close a point is to other points in its own cluster.\n",
        "\n",
        "How far that point is from points in other clusters.\n",
        "\n",
        "\n",
        "**Adjusted Rand Index (ARI)**- compares DBSCAN clusters to ground truth labels -y (for iris and synthetic data)."
      ],
      "metadata": {
        "id": "6Gha1FY8CAYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons, make_circles, make_blobs, load_iris\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "#Prepare datasets- here we are creating 4 datasets where each dataset return X,y\n",
        "datasets = {\n",
        "    \"moons\": make_moons(n_samples=500, noise=0.05, random_state=42),\n",
        "    \"circles\": make_circles(n_samples=500, noise=0.05, factor=0.5, random_state=42),\n",
        "    \"blobs\": make_blobs(n_samples=500, centers=3, random_state=42, cluster_std=1.0),\n",
        "    \"iris\": (load_iris().data, load_iris().target)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, (X, y_true) in datasets.items():\n",
        "    X = StandardScaler().fit_transform(X)  #standardizing to prevent outliers\n",
        "    db = DBSCAN(eps=0.2, min_samples=4).fit(X) #eps- radius around a point to look for its neighbors, min_samples- min no.of neighbors should be around to be considered as core point with eps.\n",
        "    labels=db.labels_ #predicted cluster labels\n",
        "\n",
        "    #only evaluate if clustering produced more than 1 cluster\n",
        "    if len(set(labels)) > 1:\n",
        "        sil=silhouette_score(X, labels)\n",
        "    else:\n",
        "        sil=-1  #invalid clustering\n",
        "\n",
        "    ari=adjusted_rand_score(y_true, labels)\n",
        "    results[name] = {\"silhouette\": sil, \"ARI\": ari}\n",
        "\n",
        "print(\"Baseline Results:\",results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc63FzviHAQt",
        "outputId": "44ff36e8-540b-43bb-b14c-7e9a9707a49c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Results: {'moons': {'silhouette': np.float64(0.3893383378360491), 'ARI': 1.0}, 'circles': {'silhouette': np.float64(0.00975341737857767), 'ARI': 0.8902038626778396}, 'blobs': {'silhouette': np.float64(0.7449470679355416), 'ARI': 0.9940241459273143}, 'iris': {'silhouette': np.float64(0.02514589229455723), 'ARI': 0.007556094556967286}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing eps = clusters merge, fewer clusters.\n",
        "\n",
        "Decreasing eps = clusters split, more noise.\n",
        "\n",
        "Increasing min_samples = fewer, stricter clusters + more noise.\n",
        "\n",
        "Decreasing min_samples = more, looser clusters."
      ],
      "metadata": {
        "id": "5rsOoiMAHTNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**\n",
        "\n",
        "To address DBSCAN’s parameter sensitivity, we systematically tuned:\n",
        "\n",
        "eps ∈ [0.1, 1.0] (step 0.1)\n",
        "\n",
        "min_samples ∈ [2, 10]\n",
        "- choose this range because they they are likely to produce meaningful clusters without excessive computation.\n",
        "\n",
        "We selected the combination with the highest Silhouette Score.\n",
        "\n",
        "**Observation:**\n",
        "\n",
        "Tuned DBSCAN discovered more meaningful clusters.\n",
        "\n",
        "Silhouette and ARI scores improved significantly.\n",
        "\n",
        "Plots showed clear separation of moons, circles, and blob clusters.\n",
        "\n",
        "For Iris, tuning reduced noise points and improved cluster purity."
      ],
      "metadata": {
        "id": "S3ls__15IiAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "tuned_results = {}\n",
        "\n",
        "for name, (X, y_true) in datasets.items():\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    best_sil = -1\n",
        "    best_params = None\n",
        "    best_ari = None\n",
        "\n",
        "    for eps in np.arange(0.1, 1.1, 0.1):\n",
        "        for min_samples in range(2, 11):\n",
        "            db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
        "            labels = db.labels_\n",
        "\n",
        "            # skip trivial clusterings (all noise or single cluster)\n",
        "            if len(set(labels)) <= 1:\n",
        "                continue\n",
        "\n",
        "            sil = silhouette_score(X, labels)\n",
        "            ari = adjusted_rand_score(y_true, labels)\n",
        "\n",
        "            if sil > best_sil:\n",
        "                best_sil = sil\n",
        "                best_params = {\"eps\": eps, \"min_samples\": min_samples}\n",
        "                best_ari = ari\n",
        "    tuned_results[name] = {\n",
        "        \"best_params\": best_params,\n",
        "        \"best_silhouette\": best_sil,\n",
        "        \"best_ARI\": best_ari\n",
        "    }\n",
        "print(\"Tuned Results:\", tuned_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlNWOgGWH3gD",
        "outputId": "b17d323a-0a61-43e5-ea2e-c761a79a7b60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned Results: {'moons': {'best_params': {'eps': np.float64(0.2), 'min_samples': 2}, 'best_silhouette': np.float64(0.3893383378360491), 'best_ARI': 1.0}, 'circles': {'best_params': {'eps': np.float64(0.2), 'min_samples': 5}, 'best_silhouette': np.float64(0.11820391875168704), 'best_ARI': 0.6798254765256385}, 'blobs': {'best_params': {'eps': np.float64(0.4), 'min_samples': 2}, 'best_silhouette': np.float64(0.8438960565792794), 'best_ARI': 1.0}, 'iris': {'best_params': {'eps': np.float64(1.0), 'min_samples': 10}, 'best_silhouette': np.float64(0.5390161166886169), 'best_ARI': 0.5503452567273898}}\n"
          ]
        }
      ]
    }
  ]
}